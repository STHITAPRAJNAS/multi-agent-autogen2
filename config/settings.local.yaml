# Database Settings (Local Development)
database_config:
  db_type: "sqlite"
  db_url: "sqlite:///local.db"
  pg_db_url: "postgresql://user:password@localhost:5432/mydatabase" # Update with your PgVector connection string
  pg_collection_name: "default_collection" # A default collection name for PgVector

# LLM Settings
llm_config:
  max_tokens: 2048
  temperature: 0.7
  OAI_CONFIG_LIST: ""
  DEFAULT_MODEL: "gemini-pro"

# Conversation Settings
conversation_config:
  history_length: 10 # Number of conversation turns to keep in history
  cost_per_token: 0.000002 # Example cost per token

# Other Settings
logging_config:
  level: "DEBUG"
  log_file: "app.log"
bedrock_config:
  ANTHROPIC_MODEL_ID: "anthropic.claude-v2"
  GEMINI_MODEL_ID: "google_gemini_pro"

# Local development settings
llm:
  provider: gemini  # Using Gemini for local development
  model: gemini-pro
  api_key: "${GEMINI_API_KEY}"  # Will be loaded from environment variable
  api_type: google  # Required for AutoGen to recognize the provider

vector_stores:
  knowledge_base:
    type: memory  # local testing
    collection_name: knowledge_base
    embedding_model: all-MiniLM-L6-v2
    dimensions: 384

  databricks_schema:
    type: memory  # local testing
    collection_name: databricks_schema
    embedding_model: all-MiniLM-L6-v2
    dimensions: 384

  graphql_schema:
    type: memory  # local testing
    collection_name: graphql_schema
    embedding_model: all-MiniLM-L6-v2
    dimensions: 384

agents:
  knowledge_retriever:
    system_prompt: "You are a knowledge retrieval expert. Use the provided context to answer questions accurately."
    max_tokens: 4000
    temperature: 0.1

  sql_generator:
    system_prompt: "You are a SQL expert. Generate accurate SQL queries based on the provided schema and requirements."
    max_tokens: 4000
    temperature: 0.1

  graphql_generator:
    system_prompt: "You are a GraphQL expert. Generate accurate GraphQL queries based on the provided schema and requirements."
    max_tokens: 4000
    temperature: 0.1

  code_generator:
    system_prompt: "You are an expert software architect and developer. Generate high-quality, production-ready code."
    max_tokens: 4000
    temperature: 0.1

  orchestrator:
    system_prompt: "You are an AI orchestrator. Analyze user questions and delegate tasks to appropriate agents."
    max_tokens: 4000
    temperature: 0.1
